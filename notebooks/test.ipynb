{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.utils.video import VideoIterator\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "FRAME_COMPRESSION = 1\n",
    "FRAME_SKIP = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = '../data/Learn English With Street Interviews! #40 What Makes you Happy_#britishenglish #howtospeakenglish.mp4'\n",
    "input_image_paths = [\n",
    "    '../data/Снимок экрана 2023-05-25 в 14.52.39.png',\n",
    "]\n",
    "output_video_path = '../data/output3.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e42c3d7ee544e7597d2118da2af92e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_face_encodings = []\n",
    "for input_image_path in tqdm(input_image_paths):\n",
    "    input_image = face_recognition.load_image_file(input_image_path)\n",
    "    input_face_encodings.extend(face_recognition.face_encodings(input_image, num_jitters=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "video_iterator = VideoIterator(input_video_path)\n",
    "video_writer = cv2.VideoWriter(\n",
    "    output_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "    video_iterator.fps,\n",
    "    (video_iterator.width, video_iterator.height),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb98fff29972428fae59588d743b8ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "face_locations = []\n",
    "face_encodings = []\n",
    "known_faces = []\n",
    "\n",
    "for i, frame in enumerate(tqdm(video_iterator)):\n",
    "    if i % FRAME_SKIP == 0:\n",
    "        small_frame = cv2.cvtColor(cv2.resize(frame, (0, 0), fx=1/FRAME_COMPRESSION, fy=1/FRAME_COMPRESSION), cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "\n",
    "        known_faces = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(input_face_encodings, face_encoding, tolerance=0.5)\n",
    "            known_faces.append(True if True in matches else False)\n",
    "    \n",
    "    # Create mask for blurred faces\n",
    "    mask = np.zeros_like(frame) - 1\n",
    "    for (top, right, bottom, left), known in zip(face_locations, known_faces):\n",
    "        if known:\n",
    "            continue\n",
    "        top *= FRAME_COMPRESSION\n",
    "        right *= FRAME_COMPRESSION\n",
    "        bottom *= FRAME_COMPRESSION\n",
    "        left *= FRAME_COMPRESSION\n",
    "        mask[top:bottom, left:right] = 0\n",
    "    # Blur frame on mask\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (45, 45), 0)\n",
    "    frame = np.where(\n",
    "        mask==np.array([255, 255, 255]),\n",
    "        frame,\n",
    "        blurred_frame\n",
    "    )\n",
    "\n",
    "    # Write frame to output video\n",
    "    video_writer.write(frame)\n",
    "\n",
    "video_writer.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = '../data/Learn English With Street Interviews! #40 What Makes you Happy_#britishenglish #howtospeakenglish.mp4'\n",
    "output_video_path = '../data/output3.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_clip = VideoFileClip(input_video_path)\n",
    "output_clip = VideoFileClip(output_video_path)\n",
    "output_clip = output_clip.set_audio(input_clip.audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../data/final3.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ../data/final3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../data/final3.mp4\n"
     ]
    }
   ],
   "source": [
    "output_clip.write_videofile(\n",
    "    '../data/final3.mp4',\n",
    "    codec='libx264', \n",
    "    audio_codec='aac', \n",
    "    temp_audiofile='temp-audio.m4a', \n",
    "    remove_temp=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sipi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
